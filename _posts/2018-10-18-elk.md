---
layout: post
title: 'elk部署'
date: 2018-10-18
author: 邬晨
color: rgb(255,210,32)
cover: 'http://on2171g4d.bkt.clouddn.com/jekyll-banner.png'
tags: elk
---
# ELK日志平台部署文档 #



## 目录 ##

- 1.为什么会有这个文章(#1.为什么会有这个文章)
  - 1.1 关于(#1.1 关于)
  - 1.2 声明(#1.2 声明)
- [2.环境准备](#2. 环境准备)
  - [2.1 系统环境](#2.1 系统环境)
  - [2.2 软件版本，路径](#2.2 软件版本，路径)
- [3.环境部署](#3. 环境部署)
  - [3.1 初始化](#3.1 初始化)
  - [3.2 JDK安装](#3.2 安装JDK)
  - [3.3 elasticsearch安装](#3.3 elasticsearch安装)
  - [3.4 logstash安装](#3.4 logstash安装)
  - [3.5 zookeeper安装](#3.5 zookeeper安装)
  - [3.6 kafka安装](#3.6 kafka安装)
  - [3.7 kibana安装](#3.7 kibana安装)
- [4.使用帮助](#4.使用帮助)

##  1.为什么会有这个文章
### 1.1 关于
为了日志可视化，提高工作效率

### 1.2 声明

文档与官方文档有冲突，请与官方文档为准
## 2. 环境准备
### 2.1 系统环境
系统：centos7.2

|   Name   | 公网IP |    内网IP     |          软件          |
| :------: | :----: | :-----------: | :--------------------: |
| es-node1 |  XXXX  | 10.46.226.77  |    jdk,es,zk,kafka     |
| es-node2 |  XXXX  | 10.26.91.126  |    jdk,es,zk,kafka     |
| es-node3 |  XXXX  |  10.27.0.39   | jdk,es,zk,kafka,kibana |
| logstash |  XXXX  | 10.80.153.218 |      jdk,logstash      |
|  kibana  |  XXXX  |  10.27.0.39   | jdk,es,zk,kafka,kibana |


内核：3.10

Yum源：清华大学开源镜像站
### 2.2 软件版本，路径

| 软件          | 版本       | 路径            |
| ------------- | ---------- | --------------- |
| JDK           | 1.8        | /usr/local/jdk  |
| elasticsearch | 6.2.2      | /usr/local/elk/ |
| logstash      | 6.2.2      | /usr/local/elk/ |
| kibana        | 6.2.2      | /usr/local/elk/ |
| zookeeper     | 3.4.11     | /usr/local/elk/ |
| kafka         | 2.12-1.0.1 | /usr/local/elk/ |

## 3. 环境部署
### 3.1 初始化
更改hostname

关闭防火墙(部署完成之后打开相应端口)，关闭selinux，

挂载数据盘到/data/目录

四台节点相互写好/etc/hosts

### 3.2 安装JDK

>### 首先把软件包上传到四个节点
>### 以下操作在四台节点都要操作


```shell
tar -xf jdk-8u162-linux-x64.tar.gz
mv jdk1.8.0_162/ /usr/local/jdk

vim /etc/profile
#最后添加
export JAVA_HOME=/usr/local/jdk
export JAVA_BIN=/usr/local/bin/jdk
export PATH=$PATH:$JAVA_HOME/bin
export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar
export JAVA_HOME JAVA_BIN PATH CLASSPATH

source /etc/profile
java -version
java version "1.8.0_162"
Java(TM) SE Runtime Environment (build 1.8.0_162-b12)
Java HotSpot(TM) 64-Bit Server VM (build 25.162-b12, mixed mode)
```


```shell
useradd elk
passwd elk
```
### 3.3 elasticsearch安装

>### 以下操作在三个es节点操作

```shell
vim /etc/security/limits.conf 
#在最后添加
* soft nproc 65536 
* hard nproc 65536
* soft nofile 65536
* hard nofile 65536
mkdir /usr/local/elk
tar -xf elasticsearch-6.2.2.tar.gz  -C /usr/local/elk/
```


```shell
echo "ulimit -SHn 65536" >> /etc/profile
ource /etc/profile
vim /etc/sysctl.conf
vm.max_map_count = 262144
vm.swappiness = 1
sysctl -p

mkdir /usr/local/elk
mkdir /data/{data,logs} -p     #创建es数据和日志目录
tar -xf elasticsearch-6.2.2.tar.gz  -C /usr/local/elk/

chown elk:elk /data/ -R
chown elk:elk  /usr/local/elk -R

vim /usr/local/elk/elasticsearch-6.6.2/config/jvm.options
#调整JVM参数，为物理机内存的一半，但不要超过31G
-Xms4g
-Xmx4g
```

>### 每个节点只有node.name与network.host不同，其余都相同

```shell
vim /usr/local/elk/elasticsearch-6.2.2/config/elasticsearch.yml
cluster.name: cluster-es                  //自定义集群名，相同集群内节点设置相同集群名
node.name: es-node1                       //自定义节点名，建议统一采用节点hostname
node.master: true                         //是否能当选master
node.data: true                           //
path.data: /data/data/                    //data存储路径
path.logs: /data/logs/                    //logs存储路径
index.number_of_shards: 5                 //设置默认索引分片个数，默认为5片。
index.number_of_replicas: 1               //设置默认索引副本个数，默认为1个副本。
bootstrap.system_call_filter: false       //系统调用过滤器，建议禁用该项检查，因为很多检查项需要Linux 3.5以上的内核。否则会报错误
#http.cors.enabled: true                  //head必须
#http.cors.allow-origin: "*"              //head必须。
network.host: 10.30.21.205                //自身IP
http.port: 9200                           //监听端口
transport.tcp.port: 9300                  //节点间交互的tcp端口，默认是9300。
discovery.zen.ping.unicast.hosts: ["10.46.226.77", "10.26.91.126", "10.27.0.39"]  //集群机器
discovery.zen.minimum_master_nodes: 2                //防止脑裂
discovery.zen.fd.ping_timeout: 180s                  //ping 的超时时间
discovery.zen.fd.ping_retries: 10                    //ping 重试的次数
discovery.zen.fd.ping_interval: 30s                  //ping 的间隔
transport.tcp.compress: true                         //设置是否压缩tcp传输时的数据，默认为false，不压缩。
http.max_content_length: 100mb                       //最大内容  默认100mb

su - elk
nohub /usr/local/elk/elasticsearch-6.2.2/bin/elasticsearch &

netstat -tunlp   #查看是否有相应端口监听

#查看集群列表
curl -XGET 'http://IP:9200/_cat/nodes?v&pretty'
```

### 3.4 logstash安装
>### 以下操作在logstash节点完成


```shell
tar -zxvf logstash-6.2.2.tar.gz -C /usr/local/elk/
mkdir /data/{data,logs}
mkdir /usr/local/elk/logstash-6.2.2/config/config
vim /usr/local/elk/logstash-6.2.2/config/jvm.options
#修改JVM信息
-Xms2g
-Xmx2g

vim /usr/local/elk/logstash-6.2.2/config/logstash.yml
#修改以下参数
http.host: "10.80.153.218"
http.port: 9600
path.data: /data/data                  #数据存放目录
pipeline.workers: 2                    #和核心数相同
pipeline.output.workers: 2             #核心数相同 默认是1/2
pipeline.batch.size: 2000              #每次发送的事件数，根据性能测试来定
pipeline.batch.delay: 5                #发送延时
path.logs: /data/logs                  #日志存放路径
log.level: info
path.config: /usr/local/elk/logstash-6.2.2/config/config   //logstash 读取配置路径

##然后在/usr/local/elk/logstash-6.2.2/config/config/路径下创建配置文件
logstash_changan.conf  logstash_pipeline.conf  logstash_tp-siteserv-access.conf  logstash_web-front.conf

chown elk:elk /usr/local/elk/ -R
chown elk:elk /data/ -R
su - elk
nohup /usr/local/elk/logstash-6.2.2/bin/logstash &
```

### 3.5 zookeeper集群安装

>### 以下操作在zk三个节点操作

```shell
tar -xf zookeeper-3.4.11.tar.gz  -C /usr/local/elk/
mv /usr/local/elk/zookeeper-3.4.11/conf/zoo_sample.cfg /usr/local/elk/zookeeper-3.4.11/conf/zoo_sample.bak
vim /usr/local/elk/zookeeper-3.4.11/conf/zoo.cfg
tickTime=2000                            #是Zookeeper独立的工作时间单元
initLimit=10                             #Follower在启动过程中，会从Leader同步所有最新数据，然后确定自己能够对外服务的起始状态，Leader允许F在 initLimit 时间内完成这个工作
syncLimit=5                              #如果L发出心跳包在syncLimit之后，还没有从F那里收到响应，那么就认为这个F已经不在线了
dataDir=/data/zookeeper                  #存放内存数据库快照的位置
clientPort=2181                          #client连接的端口
server.1=10.46.226.77:12888:13888        #这里的x是一个数字，与myid文件中的id是一致的。右边可以配置两个端口，第一个端口用于F和L之间的数据同步和其它通信，第二个端口用于Leader选举过程中投票通信
server.2=10.26.91.126:12888:13888
server.3=10.27.0.39:12888:13888

mkdir /data/zookeeper/
#根据server.x来写每个IP的myid
vim /data/zookeeper/myid
1

/usr/local/elk/zookeeper-3.4.11/bin/zkServer.sh start  #启动
netstat -tunlp                                         #查看端口状态
/usr/local/elk/zookeeper-3.4.11/bin/zkServer.sh status #查看状态  一台为Leader，两台为follower
```

### 3.6 kafka集群安装

>### 以下操作在三台kafka节点操作

```shell
tar -xf kafka_2.12-1.0.1.tgz -C /usr/local/elk/
vim /usr/local/elk/kafka_2.12-1.0.1/config/server.properties
broker.id=1                                          //每一个broker在集群中的唯一表示，为正数
delete.topic.enable=true
listeners=PLAINTEXT://10.46.226.77:9092              //监听自身IP端口
advertised.listeners=PLAINTEXT://10.46.226.77:9092   //监听自身IP端口
num.network.threads=3                                //broker处理消息的最大线程数，一般情况下数量为cpu核数
num.io.threads=8                                     //broker处理磁盘IO的线程数，数值为cpu核数2倍
socket.send.buffer.bytes=102400                      //socket的发送缓冲区，socket的调优参数SO_SNDBUFF
socket.receive.buffer.bytes=102400                   //socket的接受缓冲区，socket的调优参数SO_RCVBUFF
socket.request.max.bytes=104857600                   //socket请求的最大数值，防止serverOOM，message.max.bytes必然要小于socket.request.max.bytes，会被topic创建时的指定参数覆盖
log.dirs=/data/kafka/kafka-logs                      //日志路径
num.partitions=1                                     //每个topic的分区个数，若是在topic创建时候没有指定的话会被topic创建时的指定参数覆盖
num.recovery.threads.per.data.dir=1                  //
log.retention.hours=1                                //数据文件保留多长时间
log.segment.bytes=1073741824                         //topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖
log.retention.check.interval.ms=300000               //文件大小检查的周期时间，是否触发 log.cleanup.policy中设置的策略
zookeeper.connect=10.46.226.77:2181,10.26.91.126:2181,10.27.0.39:2181 //zookeeper集群的地址，可以是多个，多个之间用逗号分割
default.replication.factor=2                         //是否允许自动创建topic
zookeeper.connection.timeout.ms=6000                 //ZooKeeper的连接超时时间

#三台启动
mkdir /data/kafka/kafka-logs
/usr/local/elk/kafka_2.12-1.0.1/bin/kafka-server-start.sh -daemon /usr/local/elk/kafka_2.12-1.0.1/config/server.properties
```

### 3 .7 kibana安装

>### 在es-node3节点操作

```shell
tar -zxvf kibana-6.2.2-linux-x86_64.tar.gz -C /usr/local/elk
vim /usr/local/elk/kibana-6.2.2-linux-x86_64/config/kibana.yml
server.port: 5601
server.host: "10.27.0.39"
elasticsearch.url: "http://10.27.0.39:9200"

chown elk:elk /usr/local/elk/ -R
su - elk
nohub /usr/local/elk/kibana-6.2.2-linux-x86_64/bin/kibana

#浏览器打开http://ip:5601  即可~
```

至此，安装结束

## 4.使用帮助

### 4.1 es概念

#### cluster

代表一个集群，集群中有多个节点，其中有一个为主节点，这个主节点是可以通过选举产生的，主从节点是对于集群内部来说的。es的一个概念就是去中心化，字面上理解就是无中心节点，这是对于集群外部来说的，因为从外部来看es集群，在逻辑上是个整体，你与任何一个节点的通信和与整个es集群通信是等价的。

#### shards

代表索引分片，es可以把一个完整的索引分成多个分片，这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。构成分布式搜索。分片的数量只能在索引创建前指定，并且索引创建后不能更改。

#### replicas

代表索引副本，es可以设置多个索引的副本，副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。

#### recovery

代表数据恢复或叫数据重新分布，es在有节点加入或退出时会根据机器的负载对索引分片进行重新分配，挂掉的节点重新启动时也会进行数据恢复。

#### river

代表es的一个数据源，也是其它存储方式（如：数据库）同步数据到es的一个方法。它是以插件方式存在的一个es服务，通过读取river中的数据并把它索引到es中，官方的river有couchDB的，RabbitMQ的，Twitter的，Wikipedia的。

#### gateway

代表es索引快照的存储方式，es默认是先把索引存放到内存中，当内存满了时再持久化到本地硬盘。gateway对索引快照进行存储，当这个es集群关闭再重新启动时就会从gateway中读取索引备份数据。es支持多种类型的gateway，有本地文件系统（默认），分布式文件系统，Hadoop的HDFS和amazon的s3云存储服务。

#### discovery.zen

代表es的自动发现节点机制，es是一个基于p2p的系统，它先通过广播寻找存在的节点，再通过多播协议来进行节点之间的通信，同时也支持点对点的交互。

#### Transport

代表es内部节点或集群与客户端的交互方式，默认内部是使用tcp协议进行交互，同时它支持http协议（json格式）、thrift、servlet、memcached、zeroMQ等的传输协议（通过插件方式集成）。<!---->
